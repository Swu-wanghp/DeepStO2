# The Face of Deception: StO2 Dataset, Pattern Analysis, and Detection Model

### üß© Environment:
  -
    | Component | Version |
    |------------|----------|
    | OS | Ubuntu 20.04.4 LTS |
    | Python | 3.8 |
    | PyTorch | 1.10.1 |
    | CUDA | 10.2 |
    | cuDNN | 7.6.5 |
    | GPU | NVIDIA GeForce RTX 2080 Ti |
### üìä The description of StO2 Dataset and it visualization:
![Figure 1. Overview of the StO‚ÇÇ deception-detection dataset and visualization examples.](fig/basic_image.png)

**Figure 1.** Overview of the StO‚ÇÇ-based deception detection dataset.  
Each participant completes multiple **structured tasks** (e.g., personal information description, factual statements, and mock-crime scenarios) under controlled illumination and fixed camera‚Äìsubject geometry. For every trial, a **baseline segment** and a **task segment** are recorded and converted into spatial StO‚ÇÇ maps.

### üß† The Proposed PhyRIG-Net structure:
![Figure 1. Overview of the StO‚ÇÇ deception-detection dataset and visualization examples.](fig/architecture.png)

**Figure 1.** Overview of the StO‚ÇÇ-based deception detection dataset.  
Each participant completes multiple **structured tasks** (e.g., personal information description, factual statements, and mock-crime scenarios) under controlled illumination and fixed camera‚Äìsubject geometry. For every trial, a **baseline segment** and a **task segment** are recorded and converted into spatial StO‚ÇÇ maps.

### üöÄ Getting Started:
  - 
    **1. Clone this repository**
    ```bash
    git clone git@github.com:Swu-wanghp/DeepStO2.git
    cd OxyRIG-Net
    ```

    **2. Prepare environment**
    ```bash
    conda create -n env_name python=3.8
    conda activate env_name
    pip install -r requirements.txt
    ```

    **3. Upload StO‚ÇÇ data**
    The StO‚ÇÇ-Deception-Detection dataset is publicly available for academic research.
    Researchers can obtain access by contacting the corresponding author via email
    (ctong@swu.edu.cn; chentong@psych.ac.cn) and signing a License Agreement.

    **4. Download pretrained features**
    ```bash
    tar -xf features.tar.gz -C dir_to_save_feature
    ```

    **5. Training**
    ```bash
    python train.py
    ```

    **6. Inference**
    ```bash
    python test.py
    ```
    We also provide ckpts, logs, etc. to reproduce the results in the paper.
    Please download `ckpt.tar.gz`.

### üìä Dataset Overview:
  - |
    The Deception-Detection-StO‚ÇÇ dataset includes three experimental paradigms with increasing stress intensity:
    1. Personal Information Description ‚Äî low stress  
    2. Factual Statement ‚Äî moderate stress  
    3. Mock Crime ‚Äî high stress  

    All hyperspectral data were captured under calibrated halogen illumination
    to ensure uniform facial lighting and stable reflectance estimation.

### üß† Model Overview:
  - |
    OxyRIG-Net adopts a two-stage ‚Äúattribute first, reason later‚Äù framework:
    - Stage I: Physiology-guided regional attribution using ACCA and soft facial priors  
    - Stage II: Multi-relation graph reasoning over ROIs (spatial, bilateral, functional)  

    This enables interpretable and robust deception detection
    through both localized oxygenation variation and cross-regional coupling.

### üì¨ Contact:
  - |
    If you have any questions or encounter any issues,
    please feel free to open an issue or contact:
    - Hanpu Wang ‚Äî wanghp568@gmail.com  
    - Tong Chen ‚Äî ctong@swu.edu.cn / chentong@psych.ac.cn  

### üôè Acknowledgement:
  - |
    This research was supported by the Key Laboratory of Cognitive Neuroscience,
    Southwest University, and the Institute of Psychology, Chinese Academy of Sciences.
